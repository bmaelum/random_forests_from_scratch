{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspiration  \n",
    "* [How To Implement The Decision Tree Algorithm From Scratch In Python](https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/)\n",
    "\n",
    "* [Decision Trees - A simple way to visualize a decision](https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gress-gronn-kvister-1125776.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics\n",
    "Powerful as the models are easy to understand by everyone from practitioners to domain experts. A decision tree can explain exactly **why** it predicts a specific prediction. This is very useful when the main purpose is to understand what the prediction model is actually doing. \n",
    "\n",
    "This notebook will go through:\n",
    "* How to calculate and evaluate candidate split points in data\n",
    "* How to arrange splits into a decision tree structure\n",
    "* How to apply the classification and regression tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees\n",
    "Classification and Regression Trees (CART) was introduced by Leo Breiman to refer to Decision Tree algorithm that can be used for classification or regression predicitive modelling problems.  \n",
    "\n",
    "This notebook will focus on using CART for classification.  \n",
    "\n",
    "Representation of the CART model is a binary tree. For each node the binary tree can have zero, one or two child nodes.\n",
    "<img src=\"images/CART_tree_titanic_survivors.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "A node represents a single input variable X and a split point on that variable, assuming the variable is numeric. The leaf nodes(terminal nodes) of the tree contain an output variable y which is used to make a prediction.  \n",
    "\n",
    "When the tree is created it can be navigated with a new row of data following each branch with the splits until a final prediction is made. \n",
    "\n",
    "**Greedy approach**  \n",
    "Creating a binary decision tree is actually a process of splitting up the input space. A greedy approach is used to divide the space called binary splitting. This is a numerical procedure where all the values are lined up and different split points are tried and tested using a cost function.\n",
    "\n",
    "The split with the lowest cost is selected. All input variables and all possible split points are evaluated and chosen in a greedy manner based on the cost function.\n",
    "\n",
    "* **Regression:** The cost function that is minimized to choose split points is the sum squared error across all training samples that fall within the rectangle. \n",
    "\n",
    "* **Classification:** The Gini cost function is used which provides an indication of how pure the nodes are, where node purity refers to how mixed the training data assigned to each node is.\n",
    "\n",
    "Splitting continues until nodes contain a minimum number of training examples or a maximum depth is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common terms used with Decision Trees:\n",
    "1. **Root Node:** Represents entire population and this further gets divided into two or more homogeneous sets.  \n",
    "\n",
    "\n",
    "2. **Splitting:** The process of dividing a node into two or more sub-nodes  \n",
    "\n",
    "\n",
    "3. **Decision Node:** A sub-node that splits into further sub-nodes\n",
    "\n",
    "\n",
    "4. **Leaf / Terminal Node:** Nodes that do not split are called Leaf or Terminal Nodes\n",
    "\n",
    "\n",
    "5. **Pruning:** When we remove sub-nodes of a decision node.\n",
    "     \n",
    "     \n",
    "6. **Branch / Sub-tree:** A sub-section of the tree\n",
    "\n",
    "\n",
    "7. **Parent and Child Node:** A node that is split into sub-nodes is the parent node whereas sub-nodes are called child nodes.\n",
    "\n",
    "<img src=\"images/decision_tree_diagram.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Banknote Dataset\n",
    "This dataset involved predicting whether a banknote is authentic given a number of parameters taken from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
